{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Probability in Machine Learning\n",
    "\n",
    "Welcome to the Probability in Machine Learning Lab! In this lab, we will explore how probability theory plays a crucial role in machine learning. We will start with a simple coin flip example to grasp the basics and then move on to build a Bayesian email classifier. Let's dive in!\n",
    "\n",
    "## Setting Up the Environment\n",
    "\n",
    "First, let's import the necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Coin Flip Probability Example\n",
    "\n",
    "### Objective:\n",
    "To understand basic probability and Python coding through a coin flip example.\n",
    "\n",
    "### Simulating Coin Flips\n",
    "We will simulate flipping a coin 1000 times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating 1000 coin flips, 0 for 'tails' and 1 for 'heads'\n",
    "coin_flips = np.random.choice(['heads', 'tails'], size=1000)\n",
    "df_coin = pd.DataFrame({'flip_result': coin_flips})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Flip Results\n",
    "Now, let's count how many heads and tails we got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flip_result\n",
      "tails    520\n",
      "heads    480\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "flip_counts = df_coin['flip_result'].value_counts()\n",
    "print(flip_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Probabilities\n",
    "Next, we will calculate the probability of getting heads or tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Heads: 0.48\n",
      "Probability of Tails: 0.52\n"
     ]
    }
   ],
   "source": [
    "p_heads = flip_counts['heads'] / len(df_coin)\n",
    "p_tails = flip_counts['tails'] / len(df_coin)\n",
    "print(f\"Probability of Heads: {p_heads}\")\n",
    "print(f\"Probability of Tails: {p_tails}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Bayesian Email Classifier\n",
    "\n",
    "### Objective:\n",
    "Now, you will build a Bayesian email classifier to differentiate between 'spam' and 'ham' (not spam) emails.\n",
    "\n",
    "### Task 1: Exploring the Dataset\n",
    "First, load and explore the dataset. You can either find and use a dataset or use the following code to simulate a sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_length</th>\n",
       "      <th>contains_free</th>\n",
       "      <th>contains_winner</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>morning</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>morning</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>morning</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   email_length  contains_free  contains_winner time_of_day label\n",
       "0           109              0                0     morning   ham\n",
       "1            97              0                0     morning  spam\n",
       "2           112              0                0     morning  spam\n",
       "3           130              1                0   afternoon   ham\n",
       "4            95              0                1   afternoon  spam"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following code snippet creates a simulated email classification (spam and not spam) dataset with 1000 data points.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample size\n",
    "n_samples = 1000\n",
    "\n",
    "# Simulating data\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'email_length': np.random.normal(100, 20, n_samples).astype(int),\n",
    "    'contains_free': np.random.choice([0, 1], size=n_samples, p=[0.7, 0.3]),\n",
    "    'contains_winner': np.random.choice([0, 1], size=n_samples, p=[0.8, 0.2]),\n",
    "    'time_of_day': np.random.choice(['morning', 'afternoon', 'evening', 'night'], n_samples),\n",
    "    'label': np.random.choice(['spam', 'ham'], n_samples, p=[0.4, 0.6])\n",
    "}\n",
    "\n",
    "df_emails = pd.DataFrame(data)\n",
    "\n",
    "# Saving the dataset\n",
    "df.to_csv('simulated_email_dataset.csv', index=False)\n",
    "df_emails.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (Replace 'path_to_dataset' with the actual file path). You can uncomment the codes below. Notice what `df_emails.head()` is representing.\n",
    "# df_emails = pd.read_csv('path_to_dataset.csv')\n",
    "# df_emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Data Preprocessing\n",
    "You need to preprocess the data for analysis. This involves normalizing and encoding the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_length_normalized</th>\n",
       "      <th>time_of_day_encoded</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.615819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.548023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.632768</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.734463</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.536723</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   email_length_normalized  time_of_day_encoded  label_encoded\n",
       "0                 0.615819                    0              0\n",
       "1                 0.548023                    0              1\n",
       "2                 0.632768                    0              1\n",
       "3                 0.734463                    1              0\n",
       "4                 0.536723                    1              1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Normalize the 'email_length' column to be between 0 and 1\n",
    "df_emails['email_length_normalized'] = df_emails['email_length'] / df_emails['email_length'].max()\n",
    "\n",
    "# 2. Convert 'time_of_day' to numbers (encoding categories)\n",
    "time_of_day_mapping = {'morning': 0, 'afternoon': 1, 'evening': 2, 'night': 3}\n",
    "df_emails['time_of_day_encoded'] = df_emails['time_of_day'].map(time_of_day_mapping)\n",
    "\n",
    "# 3. Convert 'label' (spam or ham) to numbers: spam = 1, ham = 0\n",
    "label_encoder = LabelEncoder()\n",
    "df_emails['label_encoded'] = label_encoder.fit_transform(df_emails['label'])\n",
    "\n",
    "# Display the first few rows of the preprocessed data\n",
    "df_emails[['email_length_normalized', 'time_of_day_encoded', 'label_encoded']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Probability Calculation\n",
    "Calculate the probability of spam and ham emails in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Spam emails: 0.41\n",
      "Probability of Ham emails: 0.59\n"
     ]
    }
   ],
   "source": [
    "# Total number of emails\n",
    "total_emails = len(df_emails)\n",
    "\n",
    "# Number of spam and ham emails\n",
    "num_spam = len(df_emails[df_emails['label'] == 'spam'])\n",
    "num_ham = len(df_emails[df_emails['label'] == 'ham'])\n",
    "\n",
    "# Probability of spam and ham emails\n",
    "prob_spam = num_spam / total_emails\n",
    "prob_ham = num_ham / total_emails\n",
    "\n",
    "# Print the probabilities\n",
    "print(f\"Probability of Spam emails: {prob_spam:.2f}\")\n",
    "print(f\"Probability of Ham emails: {prob_ham:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Implementing Bayes' Theorem\n",
    "Implement Bayes' Theorem to classify emails as spam or ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email \"Buy now and get free gift\" is classified as: spam\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataset\n",
    "data = {'email': ['Buy now', 'Limited offer', 'Hello friend', 'Meeting at 10', 'Free gift' ],\n",
    "        'label': ['spam', 'spam', 'ham', 'ham', 'spam' ]}\n",
    "df = pd.DataFrame(data)\n",
    "p_spam = len(df[df['label'] == 'spam']) / len(df)\n",
    "p_ham = len(df[df['label'] == 'ham']) / len(df)\n",
    "spam_words = ' '.join(df[df['label'] == 'spam']['email']).split()\n",
    "ham_words = ' '.join(df[df['label'] == 'ham']['email']).split()\n",
    "def likelihood(word, label):\n",
    "    if label == 'spam':\n",
    "        return (spam_words.count(word) + 1) / (len(spam_words) + 2)  # Laplace smoothing\n",
    "    else:\n",
    "        return (ham_words.count(word) + 1) / (len(ham_words) + 2)\n",
    "def classify(email):\n",
    "    words = email.split()\n",
    "    p_spam_given_email = p_spam\n",
    "    p_ham_given_email = p_ham\n",
    "    for word in words:\n",
    "        p_spam_given_email *= likelihood(word, 'spam')\n",
    "        p_ham_given_email *= likelihood(word, 'ham')\n",
    "\n",
    "    return 'spam' if p_spam_given_email > p_ham_given_email else 'ham'\n",
    "\n",
    "# Example usage\n",
    "new_email = 'Buy now and get free gift'\n",
    "classification = classify(new_email)\n",
    "print(f'The email \"{new_email}\" is classified as: {classification}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Model Testing\n",
    "Test the model on a new dataset and evaluate its performance. You can use a subset of the dataset that you created or create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "                                    email predicted\n",
      "0                      Win a free iPhone       ham\n",
      "1               Let’s catch up next week       ham\n",
      "2            Exclusive deal just for you       ham\n",
      "3                  Your invoice is ready       ham\n",
      "4  Congratulations! You have won a prize       ham\n",
      "Accuracy: 0.40\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# New test dataset\n",
    "test_data = {\n",
    "    'email': [ 'Win a free iPhone',  'Let’s catch up next week',  'Exclusive deal just for you',  'Your invoice is ready',  'Congratulations! You have won a prize'],\n",
    "    'label': ['spam', 'ham', 'spam', 'ham', 'spam' ]}\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df['predicted'] = test_df['email'].apply(classify)\n",
    "print(\"Predictions:\\n\", test_df[['email', 'predicted']])\n",
    "accuracy = accuracy_score(test_df['label'], test_df['predicted'])\n",
    "precision = precision_score(test_df['label'], test_df['predicted'], pos_label='spam', average='binary', zero_division=0)\n",
    "recall = recall_score(test_df['label'], test_df['predicted'], pos_label='spam', average='binary', zero_division=0)\n",
    "f1 = f1_score(test_df['label'], test_df['predicted'], pos_label='spam', average='binary', zero_division=0)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Discussion\n",
    "1. Which probability distribution would you choose for an email classifier? Explain your answer.\n",
    "Answer: Probability Distribution Choice for an Email Classifier:\n",
    "Preferred Distribution is Multinomial Distribution\n",
    "Reason: This distribution is ideal for handling word counts in text classification, effectively capturing how often words appear in spam versus ham emails.\n",
    "2. Discuss how Bayesian updating improves the accuracy of the classifier.\n",
    "Answer: Bayesian Updating allows the model to revise its predictions as it receives new data.\n",
    "Advantages:\n",
    "Learning Over Time: The model can adjust its predictions based on new emails, improving accuracy.\n",
    "Using Existing Knowledge: It can integrate prior information, which helps when there's limited data.\n",
    "Managing Uncertainty: Regular updates lead to more accurate classifications as the model learns from ongoing data. \n",
    "3. What are the limitations of the model built in this lab?\n",
    "Answer:\n",
    "Oversimplified Assumptions: It assumes that features (words) are independent, which is often not the case.\n",
    "Limited Data: Its performance heavily relies on the training dataset's size and variety.\n",
    "Imbalance Issues: If there are far more ham emails than spam, the model may be biased towards predicting ham.\n",
    "Context Ignorance: It doesn’t consider word relationships, which can result in misclassifications.\n",
    "Static Approach: The model needs to be retrained to adapt to new data instead of updating automatically.\n",
    "Lack of Advanced Techniques: It doesn’t leverage more sophisticated natural language processing methods that could enhance results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Submit a link to your completed Jupyter Notebook file hosted on your private GitHub repository through the submission link in Blackboard."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
